{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Attention.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPAQUKhHEssb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 양방향 LSTM과 어텐션 메커니즘(BiLSTM with Attention mechanism)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjwquRLFE1np",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 100\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocab_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBWSyL8pE77t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시간이 너무 오래걸려 개수를 많이 줄였습니다.\n",
        "# (attention 동작 원리에 집중하고자..)\n",
        "X_train = X_train[:1000]\n",
        "y_train = y_train[:1000]\n",
        "X_test = X_test[:1000]\n",
        "y_test = y_test[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-TmoR9QFUn-",
        "colab_type": "code",
        "outputId": "2aedd5a5-be22-4751-b504-e33a850284a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 14, 22, 16, 43,  2,  2,\n",
              "        2,  2, 65,  2,  2, 66,  2,  4,  2, 36,  2,  5, 25,  2, 43,  2,  2,\n",
              "       50,  2,  2,  9, 35,  2,  2,  5,  2,  4,  2,  2,  2,  2,  2,  2, 39,\n",
              "        4,  2,  2,  2, 17,  2, 38, 13,  2,  4,  2, 50, 16,  6,  2,  2, 19,\n",
              "       14, 22,  4,  2,  2,  2,  4, 22, 71, 87, 12, 16, 43,  2, 38, 76, 15,\n",
              "       13,  2,  4, 22, 17,  2, 17, 12, 16,  2, 18,  2,  5, 62,  2, 12,  8,\n",
              "        2,  8,  2,  5,  4,  2,  2, 16,  2, 66,  2, 33,  4,  2, 12, 16, 38,\n",
              "        2,  5, 25,  2, 51, 36,  2, 48, 25,  2, 33,  6, 22, 12,  2, 28, 77,\n",
              "       52,  5, 14,  2, 16, 82,  2,  8,  4,  2,  2,  2, 15,  2,  4,  2,  7,\n",
              "        2,  5,  2, 36, 71, 43,  2,  2, 26,  2,  2, 46,  7,  4,  2,  2, 13,\n",
              "        2, 88,  4,  2, 15,  2, 98, 32,  2, 56, 26,  2,  6,  2,  2, 18,  4,\n",
              "        2, 22, 21,  2,  2, 26,  2,  5,  2, 30,  2, 18, 51, 36, 28,  2, 92,\n",
              "       25,  2,  4,  2, 65, 16, 38,  2, 88, 12, 16,  2,  5, 16,  2,  2,  2,\n",
              "       32, 15, 16,  2, 19,  2, 32], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCCMVpTFYqv",
        "colab_type": "code",
        "outputId": "f29d09e1-1dbb-4295-c0b2-0a8cf17782bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "for t in map(len, X_train):\n",
        "  print(t)\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddknt-v6FwrV",
        "colab_type": "code",
        "outputId": "1046187c-5835-4fa9-f7bd-ae008330d004",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('리뷰의 최대 길이 : {}'.format(max(len(l) for l in X_train)))\n",
        "print('리뷰의 평균 길이 : {}'.format(sum(map(len, X_train))/len(X_train)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 500\n",
            "리뷰의 평균 길이 : 500.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnPhSW8fGQ1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 500\n",
        "X_train = pad_sequences(X_train, maxlen=max_len)\n",
        "X_test = pad_sequences(X_test, maxlen=max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Z2cssMGd0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KerzfWi0Gn4o",
        "colab_type": "code",
        "outputId": "9bedd8aa-3339-4e1a-dc43-ef40ce2d50f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYS4Yo1wGpkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.W1 = Dense(units)\n",
        "    self.W2 = Dense(units)\n",
        "    self.V = Dense(1)\n",
        "\n",
        "  def call(self, values, query): # 단, key와 value는 같음\n",
        "    # hidden shape == (batch_size, hidden size)\n",
        "    # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "    # we are doing this to perform addition to calculate the score\n",
        "    hidden_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "    # score shape == (batch_size, max_length, 1)\n",
        "    # we get 1 at the last axis because we are applying score to self.V\n",
        "    # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "    print('values -- ', values)\n",
        "    print('query -- ', query)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # attention_weights shape == (batch_size, max_length, 1)\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "    print('attention_weights -- ', attention_weights)\n",
        "\n",
        "    # context_vector shape after sum == (batch_size, hidden_size)\n",
        "    context_vector = attention_weights * values\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    print('context_vector -- ', context_vector)\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJgRg36_KPYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Embedding, Bidirectional, LSTM, Concatenate, BatchNormalization\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras import optimizers\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGtMQPO-KT50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_input = Input(shape=(max_len,), dtype='int32')\n",
        "embedded_sequences = Embedding(vocab_size, 128, input_length=max_len)(sequence_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm9G37AeKkVF",
        "colab_type": "code",
        "outputId": "dfb4feb9-1a46-438d-d4a5-aa6b6de517f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "lstm, forward_h, forward_c, backward_h, backward_c = Bidirectional (\n",
        "                                                                    LSTM\n",
        "                                                                    (128,\n",
        "                                                                    dropout=0.3,\n",
        "                                                                    return_sequences=True,\n",
        "                                                                    return_state=True,\n",
        "                                                                    recurrent_activation='relu',\n",
        "                                                                    recurrent_initializer='glorot_uniform')\n",
        "                                                                   )(embedded_sequences)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVp2e7sAK4nI",
        "colab_type": "code",
        "outputId": "e19fb5da-f14f-4ccd-b6ff-ef4bf93d7308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(lstm.shape, forward_h.shape, forward_c.shape, backward_h.shape, backward_c.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 500, 256) (None, 128) (None, 128) (None, 128) (None, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b90Wp0gqK52P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "state_h = Concatenate()([forward_h, backward_h]) # 은닉 상태\n",
        "state_c = Concatenate()([forward_c, backward_c]) # 셀 상태"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxzoYcXDNDYf",
        "colab_type": "code",
        "outputId": "58f2d661-4bf5-4f30-89d2-442b8dacbb5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "attention = BahdanauAttention(128) # 가중치 크기 정의\n",
        "context_vector, attention_weights = attention(lstm, state_h)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "values --  Tensor(\"bidirectional_4/Identity:0\", shape=(None, 500, 256), dtype=float32)\n",
            "query --  Tensor(\"concatenate_8/Identity:0\", shape=(None, 256), dtype=float32)\n",
            "attention_weights --  Tensor(\"bahdanau_attention_4/transpose_1:0\", shape=(None, 500, 1), dtype=float32)\n",
            "context_vector --  Tensor(\"bahdanau_attention_4/Sum:0\", shape=(None, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qisjNQ74NHoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidden = BatchNormalization()(context_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9pp7aaYNMIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output = Dense(2, activation='softmax')(hidden)\n",
        "model = Model(inputs=sequence_input, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa0La0OsNN-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adam = optimizers.Adam(lr=0.001, clipnorm=1.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG0UH6YWNRwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=Adam, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TFiI6VSNTOS",
        "colab_type": "code",
        "outputId": "a5ae3ab6-8c34-4e35-8fd2-491c1d956309",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=1, batch_size=4, validation_data=(X_test, y_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "values --  Tensor(\"model_4/bidirectional_4/concat:0\", shape=(4, 500, 256), dtype=float32)\n",
            "query --  Tensor(\"model_4/concatenate_8/concat:0\", shape=(4, 256), dtype=float32)\n",
            "attention_weights --  Tensor(\"model_4/bahdanau_attention_4/transpose_1:0\", shape=(4, 500, 1), dtype=float32)\n",
            "context_vector --  Tensor(\"model_4/bahdanau_attention_4/Sum:0\", shape=(4, 256), dtype=float32)\n",
            "values --  Tensor(\"model_4/bidirectional_4/concat:0\", shape=(4, 500, 256), dtype=float32)\n",
            "query --  Tensor(\"model_4/concatenate_8/concat:0\", shape=(4, 256), dtype=float32)\n",
            "attention_weights --  Tensor(\"model_4/bahdanau_attention_4/transpose_1:0\", shape=(4, 500, 1), dtype=float32)\n",
            "context_vector --  Tensor(\"model_4/bahdanau_attention_4/Sum:0\", shape=(4, 256), dtype=float32)\n",
            "250/250 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.5170values --  Tensor(\"model_4/bidirectional_4/concat:0\", shape=(4, 500, 256), dtype=float32)\n",
            "query --  Tensor(\"model_4/concatenate_8/concat:0\", shape=(4, 256), dtype=float32)\n",
            "attention_weights --  Tensor(\"model_4/bahdanau_attention_4/transpose_1:0\", shape=(4, 500, 1), dtype=float32)\n",
            "context_vector --  Tensor(\"model_4/bahdanau_attention_4/Sum:0\", shape=(4, 256), dtype=float32)\n",
            "250/250 [==============================] - 179s 716ms/step - loss: 0.6953 - accuracy: 0.5170 - val_loss: 0.6871 - val_accuracy: 0.5260\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibbh62loNWJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}