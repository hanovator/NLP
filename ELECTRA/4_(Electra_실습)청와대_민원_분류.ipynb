{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_(BERT 실습)청와대 민원 분류.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d80b0aca9bf4082bde48389cba633dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b81c028f8db647d38c8ea726d2a42616",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_77ba587f38434bfa85ea3bcaa56ffd92",
              "IPY_MODEL_f9f792a1a7c04f88ab6b8d55e8689ef4"
            ]
          }
        },
        "b81c028f8db647d38c8ea726d2a42616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77ba587f38434bfa85ea3bcaa56ffd92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6180d1361f13419ea4ba0f56201056f3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 279173,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 279173,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df6eeed4ef774c81a02c210e95cc3f8e"
          }
        },
        "f9f792a1a7c04f88ab6b8d55e8689ef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_645fdfc6c0f545b1ba9db6e94c423344",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 279k/279k [00:00&lt;00:00, 322kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8ce1f8b310a482aafb0152c7b1aaf6d"
          }
        },
        "6180d1361f13419ea4ba0f56201056f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df6eeed4ef774c81a02c210e95cc3f8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "645fdfc6c0f545b1ba9db6e94c423344": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8ce1f8b310a482aafb0152c7b1aaf6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d1ee78590374e17a88de3a92d6f04c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_221543deb041434bb167c623e80e6d24",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e704623bdeeb495dbe2bb34985e29221",
              "IPY_MODEL_846efe239713427391fd45546599afdf"
            ]
          }
        },
        "221543deb041434bb167c623e80e6d24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e704623bdeeb495dbe2bb34985e29221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b73a28d8f126483f8f277af25840b1ab",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 51,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 51,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceb8f1b3376c46a590ea90573fbcf702"
          }
        },
        "846efe239713427391fd45546599afdf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1d86336f6ec5412884c25da684159a8c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 51.0/51.0 [00:00&lt;00:00, 1.05kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5822b7dd6f8f4fb094085456b731cdfa"
          }
        },
        "b73a28d8f126483f8f277af25840b1ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceb8f1b3376c46a590ea90573fbcf702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1d86336f6ec5412884c25da684159a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5822b7dd6f8f4fb094085456b731cdfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e56c81acdc6944658f4268abe2898bab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b402464300114e87bae2a1da2871e328",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9b29bb681a98434b99ede1f2671298e3",
              "IPY_MODEL_3c8dcfcef1fc47beb52e4b85270c1987"
            ]
          }
        },
        "b402464300114e87bae2a1da2871e328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b29bb681a98434b99ede1f2671298e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_66e8b13ecc6f479cbc0c0d98449f5e8c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 467,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 467,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_650df02ccb0c4844b228c73e61fb819a"
          }
        },
        "3c8dcfcef1fc47beb52e4b85270c1987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad296ac021204a8f80b4dc38cf951478",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 467/467 [00:01&lt;00:00, 364B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_21bf0c88765e40aa80eae383b7cd0669"
          }
        },
        "66e8b13ecc6f479cbc0c0d98449f5e8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "650df02ccb0c4844b228c73e61fb819a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad296ac021204a8f80b4dc38cf951478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "21bf0c88765e40aa80eae383b7cd0669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a58b204e6c6e40529c78c7c44cc5beca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ab8e86995e6b4333840a53969d8d7283",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_90ce7ec4075a4c85ab00115e49a39646",
              "IPY_MODEL_9a4c1d52b9114f8fb77a7a2c2a6cc14f"
            ]
          }
        },
        "ab8e86995e6b4333840a53969d8d7283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "90ce7ec4075a4c85ab00115e49a39646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d34d276c822f4499bf6d2ff16a9668bf",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 443133216,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 443133216,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18fc1bd1630641b79151899a0fa52194"
          }
        },
        "9a4c1d52b9114f8fb77a7a2c2a6cc14f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ca001b0b1f44738b39e3b89fa195bde",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 443M/443M [00:13&lt;00:00, 33.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b781adac5a44c24ad611027cc390a8c"
          }
        },
        "d34d276c822f4499bf6d2ff16a9668bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18fc1bd1630641b79151899a0fa52194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ca001b0b1f44738b39e3b89fa195bde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b781adac5a44c24ad611027cc390a8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO3MDrbfpfxV",
        "colab_type": "text"
      },
      "source": [
        "huggingface 패키지를 Colab에 설치합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AB7YtQ3rZzF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        },
        "outputId": "c5d5c19f-9547-4ed6-8512-d283ef8e2f79"
      },
      "source": [
        "!pip install transformers\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 19.8MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.8MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 2.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 3.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 3.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 16.8MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 17.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=2cb721e41c93e63bae25f2c4289e1a8e75bd32b48915b217e461c552ea20a917\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTncidebqMqT",
        "colab_type": "text"
      },
      "source": [
        "구글 드라이브와 Colab을 연동합니다.  \n",
        "https://dacon.io/ -> 교육 -> 데이터에서 청와대 관련 데이터를 다운 받으시기 바랍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JSqucXTB-jX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0794bee7-848b-43eb-e18d-f6da5c3a275b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqyrZMlpHD2v",
        "colab_type": "text"
      },
      "source": [
        "GDrive와 코랩을 연동합니다.  \n",
        "Gdrive 상의 Colab Notebooks/청와대 폴더에 Dacon에서 다운받은 train.csv와 test.csv를 업로드 해 줍니다.  \n",
        "path에 경로를 지정해주도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxCNJoLmEkCy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"gdrive/My Drive/Colab Notebooks/청와대\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_stoXnREfDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "b3ba6cd4-8b32-496a-a7bb-3f031b86721e"
      },
      "source": [
        "os.listdir(\"gdrive/My Drive/Colab Notebooks/청와대\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train.csv',\n",
              " 'sample_submission.csv',\n",
              " 'test.csv',\n",
              " 'sentiment_model.h5',\n",
              " '제출.csv']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldGY9x7NHjV-",
        "colab_type": "text"
      },
      "source": [
        "train 데이터와 test 데이터를 pandas dataframe 형식으로 불러오도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpT3_4GOE0iH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(os.path.join(path,\"train.csv\"))\n",
        "test = pd.read_csv(os.path.join(path, \"test.csv\"))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZ9gzbgFLMy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f90f1142-e3fb-42e6-f5b7-8395003c006c"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>category</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  category                                               data\n",
              "0      0         2  신혼부부위한 주택정책 보다 보육시설 늘려주세요.. 국민세금으로 일부를 위한 정책펴지...\n",
              "1      1         0  학교이름에 '남자'도 붙여주세요. 울산여자중학교에 재학중인 학생입니다 최근 양성평등...\n",
              "2      2         1  빙상연맹, 대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요.. 최근 동계올...\n",
              "3      3         1  티비 12세,15세 관람가도 연령확인 의무화 하자.. 제기 에전에 티비를 보다가 잠...\n",
              "4      4         1  무더운 여름철엔 남성들도 시원한 자율복장을 해야. 무더운 여름철에는 남성들도 노넥타..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Q5EdVoFNR2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e8e34d6f-c6c1-44b0-a397-aefe69be6934"
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\n법으로 인해 보호받지 못...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\n*지역 어린...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               data\n",
              "0      0  소년법 폐지해주세요. 법 아래에서 보호받아야 할 아이들이\\n법으로 인해 보호받지 못...\n",
              "1      1  국공립 유치원 증설에 관하여. 국공립 유치원 부지 학보와건립및 증설에\\n*지역 어린...\n",
              "2      2                   나경원파면. 나경원의원의  동계올림픽 위원을 파면해 주세요\n",
              "3      3  국민위원에가 삼성편만들어요. 삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...\n",
              "4      4  방과후,유치원,어린이집 영어교육을 유지시켜주세요. 저는 아이 셋 키우는 평범한 주부..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbC6R_MwHqCX",
        "colab_type": "text"
      },
      "source": [
        "train 데이터와 test 데이터를 전처리하도록 하겠습니다.  \n",
        "특수 문자들을 제거하고, 띄어쓰기가 많은 부분만 간단히 전처리 해주도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puef29XjFX4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['data'] = train['data'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \", regex=True)\n",
        "test['data'] = test['data'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', \" \", regex=True)\n",
        "train['data'] = train['data'].str.replace(r'\\t+', \" \", regex=True)\n",
        "test['data'] = test['data'].str.replace(r'\\t+', \" \", regex=True)\n",
        "train['data'] = train['data'].str.replace(r'[\\\\n]+',\" \", regex=True)\n",
        "test['data'] = test['data'].str.replace(r'[\\\\n]+',\" \", regex=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g8kk5YOHzgj",
        "colab_type": "text"
      },
      "source": [
        "전처리가 어느정도 된 것을 확인하실 수 있겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-QsL_-F_k5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52694511-4c1e-408d-da4f-170cf8a02668"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>category</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>신혼부부위한 주택정책 보다 보육시설 늘려주세요  국민세금으로 일부를 위한 정책펴지 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>학교이름에  남자 도 붙여주세요  울산여자중학교에 재학중인 학생입니다 최근 양성평등...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>빙상연맹  대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요  최근 동계올림...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>티비 12세 15세 관람가도 연령확인 의무화 하자  제기 에전에 티비를 보다가 잠시...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>무더운 여름철엔 남성들도 시원한 자율복장을 해야  무더운 여름철에는 남성들도 노넥타...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index  category                                               data\n",
              "0      0         2  신혼부부위한 주택정책 보다 보육시설 늘려주세요  국민세금으로 일부를 위한 정책펴지 ...\n",
              "1      1         0  학교이름에  남자 도 붙여주세요  울산여자중학교에 재학중인 학생입니다 최근 양성평등...\n",
              "2      2         1  빙상연맹  대한축구협회등 각종 체육협회의 비리를 철저하게 밝혀주세요  최근 동계올림...\n",
              "3      3         1  티비 12세 15세 관람가도 연령확인 의무화 하자  제기 에전에 티비를 보다가 잠시...\n",
              "4      4         1  무더운 여름철엔 남성들도 시원한 자율복장을 해야  무더운 여름철에는 남성들도 노넥타..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6VPeH7G1r-P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "42674a9e-7169-400c-9d15-740d0c8ad7b3"
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>소년법 폐지해주세요  법 아래에서 보호받아야 할 아이들이  법으로 인해 보호받지 못...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>국공립 유치원 증설에 관하여  국공립 유치원 부지 학보와건립및 증설에   지역 어린...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>나경원파면  나경원의원의  동계올림픽 위원을 파면해 주세요</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>국민위원에가 삼성편만들어요  삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>방과후 유치원 어린이집 영어교육을 유지시켜주세요  저는 아이 셋 키우는 평범한 주부...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                               data\n",
              "0      0  소년법 폐지해주세요  법 아래에서 보호받아야 할 아이들이  법으로 인해 보호받지 못...\n",
              "1      1  국공립 유치원 증설에 관하여  국공립 유치원 부지 학보와건립및 증설에   지역 어린...\n",
              "2      2                   나경원파면  나경원의원의  동계올림픽 위원을 파면해 주세요\n",
              "3      3  국민위원에가 삼성편만들어요  삼성에서 11년간  일하고 혈암과 백혈병 진단을 받은 ...\n",
              "4      4  방과후 유치원 어린이집 영어교육을 유지시켜주세요  저는 아이 셋 키우는 평범한 주부..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_fcqYvQzGz2",
        "colab_type": "text"
      },
      "source": [
        "## 버트 인풋 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vtecm3zH2bz",
        "colab_type": "text"
      },
      "source": [
        "huggingface에 쓸 모델과 토크나이저를 불러옵니다.  \n",
        "그저 실행만 해주시면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Z6MKRMRuQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = u'▁'\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        self.max_len_single_sentence = self.max_len - 2  # take into account special tokens\n",
        "        self.max_len_sentences_pair = self.max_len - 3  # take into account special tokens\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A RoBERTa sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A BERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2ngMUPmH-TX",
        "colab_type": "text"
      },
      "source": [
        "토크나이저를 불러옵니다. kobert를 활용하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8_c0W0aKDKK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "4d80b0aca9bf4082bde48389cba633dd",
            "b81c028f8db647d38c8ea726d2a42616",
            "77ba587f38434bfa85ea3bcaa56ffd92",
            "f9f792a1a7c04f88ab6b8d55e8689ef4",
            "6180d1361f13419ea4ba0f56201056f3",
            "df6eeed4ef774c81a02c210e95cc3f8e",
            "645fdfc6c0f545b1ba9db6e94c423344",
            "c8ce1f8b310a482aafb0152c7b1aaf6d",
            "0d1ee78590374e17a88de3a92d6f04c9",
            "221543deb041434bb167c623e80e6d24",
            "e704623bdeeb495dbe2bb34985e29221",
            "846efe239713427391fd45546599afdf",
            "b73a28d8f126483f8f277af25840b1ab",
            "ceb8f1b3376c46a590ea90573fbcf702",
            "1d86336f6ec5412884c25da684159a8c",
            "5822b7dd6f8f4fb094085456b731cdfa"
          ]
        },
        "outputId": "fd689d31-c326-41e9-97ea-be3cd34bd2f3"
      },
      "source": [
        "#tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')\n",
        "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-discriminator\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d80b0aca9bf4082bde48389cba633dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=279173.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d1ee78590374e17a88de3a92d6f04c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=51.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils.py:831: FutureWarning: Parameter max_len is deprecated and will be removed in a future release. Use model_max_length instead.\n",
            "  category=FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDtEz4uLIIXo",
        "colab_type": "text"
      },
      "source": [
        "train 데이터를 버트 인풋에 맞게 변경해줍니다.  \n",
        "즉, 문장을 버트 인풋에 맞게 토큰, 마스크, 세그먼트로 변환해 주겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFFokLO0sj_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "186c3366-c866-4756-d517-170b951d5bf7"
      },
      "source": [
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "    \n",
        "    SEQ_LEN = 512 #SEQ_LEN : 버트에 들어갈 인풋의 길이\n",
        "    \n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        # token : 문장을 토큰화함\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\n",
        "       \n",
        "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        \n",
        "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        \n",
        "        # 정답(긍정 : 1 부정 0)을 targets 변수에 저장해 줌\n",
        "        targets.append(data_df[LABEL_COLUMN][i])\n",
        "\n",
        "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    return [tokens, masks, segments], targets\n",
        "\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y\n",
        "\n",
        "SEQ_LEN = 512\n",
        "BATCH_SIZE = 20\n",
        "# 긍부정 문장을 포함하고 있는 칼럼\n",
        "DATA_COLUMN = \"data\"\n",
        "# 긍정인지 부정인지를 (1=긍정,0=부정) 포함하고 있는 칼럼\n",
        "LABEL_COLUMN = \"category\"\n",
        "\n",
        "# train 데이터를 버트 인풋에 맞게 변환\n",
        "train_x, train_y = load_data(train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [01:28<00:00, 449.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT4FhL4hzPMQ",
        "colab_type": "text"
      },
      "source": [
        "## 버트를 활용한 민원분류 모델 만들기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQXkHsfS1L7y",
        "colab_type": "text"
      },
      "source": [
        "버트 훈련을 빠르게 하기 위해, TPU를 사용하도록 하겠습니다.  \n",
        "TPU 사용을 원치 않으시면 TPU 관련된 부분은 실행하시지 않으면 되겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mNtsjwYecfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertConfig(PretrainedConfig):\n",
        "    r\"\"\"\n",
        "        This is the configuration class to store the configuration of a :class:`~transformers.BertModel`.\n",
        "        It is used to instantiate an BERT model according to the specified arguments, defining the model\n",
        "        architecture. Instantiating a configuration with the defaults will yield a similar configuration to that of\n",
        "        the BERT `bert-base-uncased <https://huggingface.co/bert-base-uncased>`__ architecture.\n",
        "\n",
        "        Configuration objects inherit from  :class:`~transformers.PretrainedConfig` and can be used\n",
        "        to control the model outputs. Read the documentation from  :class:`~transformers.PretrainedConfig`\n",
        "        for more information.\n",
        "\n",
        "\n",
        "        Args:\n",
        "            vocab_size (:obj:`int`, optional, defaults to 30522):\n",
        "                Vocabulary size of the BERT model. Defines the different tokens that\n",
        "                can be represented by the `inputs_ids` passed to the forward method of :class:`~transformers.BertModel`.\n",
        "            hidden_size (:obj:`int`, optional, defaults to 768):\n",
        "                Dimensionality of the encoder layers and the pooler layer.\n",
        "            num_hidden_layers (:obj:`int`, optional, defaults to 12):\n",
        "                Number of hidden layers in the Transformer encoder.\n",
        "            num_attention_heads (:obj:`int`, optional, defaults to 12):\n",
        "                Number of attention heads for each attention layer in the Transformer encoder.\n",
        "            intermediate_size (:obj:`int`, optional, defaults to 3072):\n",
        "                Dimensionality of the \"intermediate\" (i.e., feed-forward) layer in the Transformer encoder.\n",
        "            hidden_act (:obj:`str` or :obj:`function`, optional, defaults to \"gelu\"):\n",
        "                The non-linear activation function (function or string) in the encoder and pooler.\n",
        "                If string, \"gelu\", \"relu\", \"swish\" and \"gelu_new\" are supported.\n",
        "            hidden_dropout_prob (:obj:`float`, optional, defaults to 0.1):\n",
        "                The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.\n",
        "            attention_probs_dropout_prob (:obj:`float`, optional, defaults to 0.1):\n",
        "                The dropout ratio for the attention probabilities.\n",
        "            max_position_embeddings (:obj:`int`, optional, defaults to 512):\n",
        "                The maximum sequence length that this model might ever be used with.\n",
        "                Typically set this to something large just in case (e.g., 512 or 1024 or 2048).\n",
        "            type_vocab_size (:obj:`int`, optional, defaults to 2):\n",
        "                The vocabulary size of the `token_type_ids` passed into :class:`~transformers.BertModel`.\n",
        "            initializer_range (:obj:`float`, optional, defaults to 0.02):\n",
        "                The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
        "            layer_norm_eps (:obj:`float`, optional, defaults to 1e-12):\n",
        "                The epsilon used by the layer normalization layers.\n",
        "\n",
        "        Example::\n",
        "\n",
        "            from transformers import BertModel, BertConfig\n",
        "\n",
        "            # Initializing a BERT bert-base-uncased style configuration\n",
        "            configuration = BertConfig()\n",
        "\n",
        "            # Initializing a model from the bert-base-uncased style configuration\n",
        "            model = BertModel(configuration)\n",
        "\n",
        "            # Accessing the model configuration\n",
        "            configuration = model.config\n",
        "    \"\"\"\n",
        "    model_type = \"bert\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size=30522,\n",
        "        hidden_size=768,\n",
        "        num_hidden_layers=12,\n",
        "        num_attention_heads=12,\n",
        "        intermediate_size=3072,\n",
        "        hidden_act=\"gelu\",\n",
        "        hidden_dropout_prob=0.1,\n",
        "        attention_probs_dropout_prob=0.1,\n",
        "        max_position_embeddings=512,\n",
        "        type_vocab_size=2,\n",
        "        initializer_range=0.02,\n",
        "        layer_norm_eps=1e-12,\n",
        "        pad_token_id=0,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(pad_token_id=pad_token_id, **kwargs)\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.num_attention_heads = num_attention_heads\n",
        "        self.hidden_act = hidden_act\n",
        "        self.intermediate_size = intermediate_size\n",
        "        self.hidden_dropout_prob = hidden_dropout_prob\n",
        "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
        "        self.max_position_embeddings = max_position_embeddings\n",
        "        self.type_vocab_size = type_vocab_size\n",
        "        self.initializer_range = initializer_range\n",
        "        self.layer_norm_eps = layer_norm_eps"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe5RrU4KedVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TFBertPooler(tf.keras.layers.Layer):\n",
        "    def __init__(self, config, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dense = tf.keras.layers.Dense(\n",
        "            config.hidden_size,\n",
        "            kernel_initializer=\"random_uniform\",\n",
        "            activation=\"tanh\",\n",
        "            name=\"dense\",\n",
        "        )\n",
        "\n",
        "    def call(self, hidden_states):\n",
        "        # We \"pool\" the model by simply taking the hidden state corresponding\n",
        "        # to the first token.\n",
        "        first_token_tensor = hidden_states[:, 0]\n",
        "        pooled_output = self.dense(first_token_tensor)\n",
        "        return pooled_output"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pavfaWfyKxR_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "9d63a5cf-7157-4dce-a036-7023d5a2c960"
      },
      "source": [
        "# TPU 객체 만들기\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.88.58:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.104.88.58:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f41a1fbeba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUKSC6cC1T5c",
        "colab_type": "text"
      },
      "source": [
        "감정 분석에 맞는 버트 모형을 리턴하는 함수를 정의하도록 하겠습니다.  \n",
        "TPU를 활용하려면 함수로 묶어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90uerGX4Rl2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import ElectraModel, ElectraTokenizer\n",
        "def create_sentiment_bert():\n",
        "  # 버트 pretrained 모델 로드\n",
        "  #model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
        "  model = TFElectraModel.from_pretrained('monologg/koelectra-base-discriminator', from_pt=True)\n",
        "  # 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
        "  token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "  mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "  segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "  # 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
        "  bert_outputs = model([token_inputs, mask_inputs, segment_inputs])\n",
        "\n",
        "  config = BertConfig()\n",
        "  cc = TFBertPooler(config)\n",
        "\n",
        "  sequence_output = bert_outputs[0]\n",
        "  pooled_output = cc(sequence_output)\n",
        "\n",
        "  bert_outputs = (sequence_output, pooled_output,) + bert_outputs[1:]\n",
        "  bert_outputs\n",
        "\n",
        "  bert_outputs = bert_outputs[1]\n",
        "\n",
        "  sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n",
        "  sentiment_first = tf.keras.layers.Dense(3, activation='softmax', kernel_initializer=tf.keras.initializers.TruncatedNormal(0.02))(sentiment_drop)\n",
        "  sentiment_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
        "  # 옵티마이저는 간단하게 Adam 옵티마이저 활용\n",
        "  sentiment_model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.00001), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "  return sentiment_model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls-b8MRh0Ymj",
        "colab_type": "text"
      },
      "source": [
        "## 훈련 및 성능 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG2m2HL6CJF5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e56c81acdc6944658f4268abe2898bab",
            "b402464300114e87bae2a1da2871e328",
            "9b29bb681a98434b99ede1f2671298e3",
            "3c8dcfcef1fc47beb52e4b85270c1987",
            "66e8b13ecc6f479cbc0c0d98449f5e8c",
            "650df02ccb0c4844b228c73e61fb819a",
            "ad296ac021204a8f80b4dc38cf951478",
            "21bf0c88765e40aa80eae383b7cd0669",
            "a58b204e6c6e40529c78c7c44cc5beca",
            "ab8e86995e6b4333840a53969d8d7283",
            "90ce7ec4075a4c85ab00115e49a39646",
            "9a4c1d52b9114f8fb77a7a2c2a6cc14f",
            "d34d276c822f4499bf6d2ff16a9668bf",
            "18fc1bd1630641b79151899a0fa52194",
            "1ca001b0b1f44738b39e3b89fa195bde",
            "0b781adac5a44c24ad611027cc390a8c"
          ]
        },
        "outputId": "4606a227-998b-4ee9-c67d-435ae7103465"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "# TPU를 활용하기 위해 context로 묶어주기\n",
        "with strategy.scope():\n",
        "  \n",
        "  sentiment_model = create_sentiment_bert()\n",
        "  sentiment_model.fit(train_x, train_y, epochs=16, shuffle=False, batch_size=100)\n",
        "  sentiment_model.save_weights(os.path.join(path,\"sentiment_model.h5\"))\n",
        "      "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e56c81acdc6944658f4268abe2898bab",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a58b204e6c6e40529c78c7c44cc5beca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443133216.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/16\n",
            "400/400 [==============================] - 184s 461ms/step - loss: 0.5503 - sparse_categorical_accuracy: 0.7518\n",
            "Epoch 2/16\n",
            "400/400 [==============================] - 185s 461ms/step - loss: 0.2972 - sparse_categorical_accuracy: 0.8828\n",
            "Epoch 3/16\n",
            "400/400 [==============================] - 185s 461ms/step - loss: 0.2602 - sparse_categorical_accuracy: 0.8968\n",
            "Epoch 4/16\n",
            "400/400 [==============================] - 185s 461ms/step - loss: 0.2292 - sparse_categorical_accuracy: 0.9093\n",
            "Epoch 5/16\n",
            "400/400 [==============================] - 185s 461ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9209\n",
            "Epoch 6/16\n",
            "400/400 [==============================] - 185s 461ms/step - loss: 0.1722 - sparse_categorical_accuracy: 0.9313\n",
            "Epoch 7/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.1495 - sparse_categorical_accuracy: 0.9394\n",
            "Epoch 8/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.1384 - sparse_categorical_accuracy: 0.9439\n",
            "Epoch 9/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.1189 - sparse_categorical_accuracy: 0.9504\n",
            "Epoch 10/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.1074 - sparse_categorical_accuracy: 0.9559\n",
            "Epoch 11/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9616\n",
            "Epoch 12/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0780 - sparse_categorical_accuracy: 0.9683\n",
            "Epoch 13/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0685 - sparse_categorical_accuracy: 0.9716\n",
            "Epoch 14/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9757\n",
            "Epoch 15/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0543 - sparse_categorical_accuracy: 0.9779\n",
            "Epoch 16/16\n",
            "400/400 [==============================] - 185s 462ms/step - loss: 0.0491 - sparse_categorical_accuracy: 0.9794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6ZvEpA-zrPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 만약 TPU 사용을 원치 않는다면\n",
        "# sentiment_model = create_sentiment_bert()\n",
        "# sentiment_model.fit(train_x, train_y, epochs=3, shuffle=False, batch_size=20)\n",
        "# sentiment_model.save_weights(os.path.join(path,\"sentiment_model.h5\"))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Gv3m_34nIX",
        "colab_type": "text"
      },
      "source": [
        "우리가 훈련한 버트 모델을 적용하기 위해, Test 데이터를 버트 인풋에 맞게 변환하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjv6RMR1jYIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "\n",
        "        token = tokenizer.encode(data_df[DATA_COLUMN][i], max_length=SEQ_LEN, pad_to_max_length=True)\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        segments.append(segment)\n",
        "        masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "SEQ_LEN = 512\n",
        "DATA_COLUMN = 'data'\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def predict_load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "    return data_x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqPMLqtR76JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f49abf51-0513-49ec-a10e-60bdf6920e32"
      },
      "source": [
        "test_set = predict_load_data(test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5000/5000 [00:11<00:00, 434.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nyqBoQD4tz1",
        "colab_type": "text"
      },
      "source": [
        "test 데이터를 BERT 모형을 활용해서 카테고리(0:인권/성평등, 1:문화/예술/체육/언론, 2: 육아/교육)를 예측한 후 Dacon에 파일을 제출해 보도록 하겠습니다.  \n",
        "먼저 \"sample_submission.csv\"라는 제출 파일을 로드하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVtm4HTfRqvX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.read_csv(os.path.join(path,\"sample_submission.csv\"))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKwNRjlkSxwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "if \"bert\" not in os.listdir():\n",
        "  os.makedirs(\"bert\")\n",
        "else:\n",
        "  pass\n",
        "\n",
        "def copytree(src, dst, symlinks=False, ignore=None):\n",
        "    for item in os.listdir(src):\n",
        "        s = os.path.join(src, item)\n",
        "        d = os.path.join(dst, item)\n",
        "        if os.path.isdir(s):\n",
        "            shutil.copytree(s, d, symlinks, ignore)\n",
        "        else:\n",
        "            shutil.copy2(s, d)\n",
        "\n",
        "copytree(path, \"bert\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGi7gRaPR-ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "14cd9307-8d1b-400b-af59-60f7ca6e9828"
      },
      "source": [
        "import sys\n",
        "mod = sys.modules[__name__]\n",
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)\n",
        "# TPU를 활용하기 위해 context로 묶어주기\n",
        "with strategy.scope():\n",
        "  sentiment_model = create_sentiment_bert()\n",
        "  \n",
        "  sentiment_model.load_weights(os.path.join(\"bert\", \"sentiment_model.h5\"))\n",
        "  setattr(mod, 'model', sentiment_model)\n",
        "  setattr(mod, 'pred_', sentiment_model.predict(test_set, batch_size=1))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piYkhTp30Iaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 만약 TPU를 사용하지 않는다면\n",
        "# sentiment_model = create_sentiment_bert()\n",
        "  \n",
        "# sentiment_model.load_weights(os.path.join(\"bert\", \"sentiment_model.h5\"))\n",
        "# setattr(mod, 'model', sentiment_model)\n",
        "# setattr(mod, 'pred_', sentiment_model.predict(test_set, batch_size=1))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0sbkS7DLTrU",
        "colab_type": "text"
      },
      "source": [
        "버트 모형에서 예측 결과를 평균해주는 함수를 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYE8BOZooGtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_answer_label(*preds):\n",
        "  preds_sum = np.zeros(preds[0].shape[0])\n",
        "  for pred in preds:\n",
        "    preds_sum += np.argmax(pred, axis=-1)\n",
        "  return np.round(preds_sum/len(preds), 0).astype(int)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrS-SPzFpb1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission['category'] = mean_answer_label(pred_)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQi88DgbLY4a",
        "colab_type": "text"
      },
      "source": [
        "최종 Dacon에 제출할 파일을 csv파일로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3lyIs_SpkVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(os.path.join(path, \"제출.csv\"), index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaXYj07FMVmh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}