{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppymtrexzTaX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85a5b4e5-7765-48bf-9768-02220440d87a"
      },
      "source": [
        "import pandas as pd\n",
        "lines= pd.read_csv('fra.txt', names=['src', 'tar','etc'], sep='\\t')\n",
        "len(lines)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "175623"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTpdM6G_z9DB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "fb8398ea-3cd2-43c9-85dd-4d74f7f3703d"
      },
      "source": [
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "      <th>etc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36727</th>\n",
              "      <td>Meet me in the lobby.</td>\n",
              "      <td>Rejoins-moi dans le hall.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46133</th>\n",
              "      <td>Can't you see I'm busy?</td>\n",
              "      <td>Ne pouvez-vous voir que je suis occupée ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50023</th>\n",
              "      <td>That could be anything.</td>\n",
              "      <td>Ça pouvait être n'importe quoi.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25396</th>\n",
              "      <td>Now it's your turn.</td>\n",
              "      <td>C'est maintenant ton tour.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35865</th>\n",
              "      <td>I'll be your teacher.</td>\n",
              "      <td>Je vais être votre institutrice.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23725</th>\n",
              "      <td>I couldn't breathe.</td>\n",
              "      <td>Je ne pourrais pas respirer.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58363</th>\n",
              "      <td>Where's the book I need?</td>\n",
              "      <td>Où se trouve le livre dont j'ai besoin ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>No way!</td>\n",
              "      <td>Il n'en est pas question !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38921</th>\n",
              "      <td>Why did you eat that?</td>\n",
              "      <td>Pourquoi est-ce que tu as mangé ça ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55244</th>\n",
              "      <td>I won't let this happen.</td>\n",
              "      <td>Je ne laisserai pas ceci se produire.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src  ...                                                etc\n",
              "36727     Meet me in the lobby.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "46133   Can't you see I'm busy?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "50023   That could be anything.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "25396       Now it's your turn.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "35865     I'll be your teacher.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "23725       I couldn't breathe.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "58363  Where's the book I need?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "62                      No way!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "38921     Why did you eat that?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "55244  I won't let this happen.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYdTkw-81_HL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "23bad4b4-7a0c-4a5c-a9f6-62c354a523a3"
      },
      "source": [
        "lines[0:5]['src']"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Go.\n",
              "1     Hi.\n",
              "2     Hi.\n",
              "3    Run!\n",
              "4    Run!\n",
              "Name: src, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jpT1nvt0i3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "8efab23f-3f59-49e2-b014-8420ae8c6012"
      },
      "source": [
        "lines.tar = lines.tar.apply(lambda x : '\\t'+x+'\\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "      <th>etc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49077</th>\n",
              "      <td>It isn't for beginners.</td>\n",
              "      <td>\\tCe n'est pas pour les débutants.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39000</th>\n",
              "      <td>You are not a doctor.</td>\n",
              "      <td>\\tVous n’êtes pas un médecin.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36007</th>\n",
              "      <td>I'm going to college.</td>\n",
              "      <td>\\tJe vais à l'Université.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10736</th>\n",
              "      <td>I didn't see it.</td>\n",
              "      <td>\\tJe ne l'ai pas vu.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34851</th>\n",
              "      <td>I don't believe this.</td>\n",
              "      <td>\\tJe n'y crois pas.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45150</th>\n",
              "      <td>Where is the bus stop?</td>\n",
              "      <td>\\tOù se trouve l'arrêt de bus ?\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17522</th>\n",
              "      <td>You're beautiful.</td>\n",
              "      <td>\\tVous êtes belles.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40405</th>\n",
              "      <td>He cleared his throat.</td>\n",
              "      <td>\\tIl s'est éclairci la voix.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18110</th>\n",
              "      <td>Don't go in there.</td>\n",
              "      <td>\\tNe rentre pas là-dedans.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55201</th>\n",
              "      <td>I wasn't busy last week.</td>\n",
              "      <td>\\tJe n'étais pas occupé la semaine dernière.\\n</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src  ...                                                etc\n",
              "49077   It isn't for beginners.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #7...\n",
              "39000     You are not a doctor.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "36007     I'm going to college.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "10736          I didn't see it.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "34851     I don't believe this.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "45150    Where is the bus stop?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "17522         You're beautiful.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #8...\n",
              "40405    He cleared his throat.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "18110        Don't go in there.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "55201  I wasn't busy last week.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYjcIgQe08IH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del lines['etc']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK6UXliR2WDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "a7a35f51-3f6c-473a-b037-2e6fea095f6d"
      },
      "source": [
        "lines[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go.</td>\n",
              "      <td>\\tVa !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>\\tSalut !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>\\tSalut.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>\\tCours !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Run!</td>\n",
              "      <td>\\tCourez !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Who?</td>\n",
              "      <td>\\tQui ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Wow!</td>\n",
              "      <td>\\tÇa alors !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Fire!</td>\n",
              "      <td>\\tAu feu !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Help!</td>\n",
              "      <td>\\tÀ l'aide !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Jump.</td>\n",
              "      <td>\\tSaute.\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     src             tar\n",
              "0    Go.        \\tVa !\\n\n",
              "1    Hi.     \\tSalut !\\n\n",
              "2    Hi.      \\tSalut.\\n\n",
              "3   Run!     \\tCours !\\n\n",
              "4   Run!    \\tCourez !\\n\n",
              "5   Who?       \\tQui ?\\n\n",
              "6   Wow!  \\tÇa alors !\\n\n",
              "7  Fire!    \\tAu feu !\\n\n",
              "8  Help!  \\tÀ l'aide !\\n\n",
              "9  Jump.      \\tSaute.\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_VrRmAK2ci8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "src_vocab = set()\n",
        "for line in lines.src:\n",
        "  for char in line:\n",
        "    src_vocab.add(char)\n",
        "\n",
        "tar_vocab = set()\n",
        "for line in lines.tar:\n",
        "  for char in line:\n",
        "    tar_vocab.add(char)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvP-LpEq3EEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc09d42a-74cb-44d3-c59f-cf16e4ef9c17"
      },
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print(src_vocab_size)\n",
        "print(tar_vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfFfriBK3OQu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6ed882a5-ecc4-497d-a016-bb5a73257fb9"
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'R': 1, '4': 2, '0': 3, 'p': 4, 'g': 5, 'l': 6, 'E': 7, '-': 8, 'H': 9, '3': 10, 'é': 11, 'a': 12, 'f': 13, 'G': 14, '9': 15, '%': 16, 'z': 17, '$': 18, '8': 19, '?': 20, 'h': 21, 'o': 22, '1': 23, 'K': 24, 'B': 25, 'Z': 26, 'e': 27, ',': 28, 'A': 29, ' ': 30, 'Y': 31, ':': 32, 'P': 33, 'J': 34, 'y': 35, 'N': 36, '.': 37, 't': 38, 's': 39, 'S': 40, 'i': 41, 'c': 42, \"'\": 43, 'U': 44, 'n': 45, 'D': 46, 'W': 47, '2': 48, 'L': 49, 'O': 50, '’': 51, 'M': 52, '€': 53, 'V': 54, '\"': 55, 'F': 56, 'Q': 57, 'X': 58, '&': 59, 'm': 60, 'I': 61, '7': 62, 'T': 63, 'j': 64, 'x': 65, 'u': 66, 'r': 67, 'C': 68, '!': 69, '6': 70, 'w': 71, 'k': 72, 'q': 73, '5': 74, 'v': 75, 'd': 76, '/': 77, 'b': 78}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi2psYL43Vgi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87896e33-18ce-4f9d-c2a2-a25364ec6185"
      },
      "source": [
        "encoder_input = []\n",
        "for line in lines.src:\n",
        "  temp_X = []\n",
        "  for w in line:\n",
        "    temp_X.append(src_to_index[w])\n",
        "  encoder_input.append(temp_X)\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[14, 22, 37], [9, 41, 37], [9, 41, 37], [1, 66, 45, 69], [1, 66, 45, 69]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwoUIQE64s_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c7fa6d79-658b-4d05-fb92-be77ed097d43"
      },
      "source": [
        "decoder_input = []\n",
        "for line in lines.tar:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      temp_X.append(tar_to_index[w])\n",
        "    decoder_input.append(temp_X)\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[63, 100, 81, 87, 72, 23], [63, 66, 81, 78, 17, 39, 87, 72, 23], [63, 66, 81, 78, 17, 39, 38, 23], [63, 48, 5, 17, 103, 65, 75, 72, 23], [63, 48, 5, 17, 103, 35, 31, 75, 72, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbW7PIUe5U_l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1c79b1f1-877d-4234-f617-0fda4ae22aa5"
      },
      "source": [
        "lines.tar"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                                               \\tVa !\\n\n",
              "1                                            \\tSalut !\\n\n",
              "2                                             \\tSalut.\\n\n",
              "3                                            \\tCours !\\n\n",
              "4                                           \\tCourez !\\n\n",
              "                              ...                       \n",
              "59995           \\tDonnez-moi un café, s'il vous plait.\\n\n",
              "59996              \\tDonnez-moi un café, je vous prie.\\n\n",
              "59997    \\tDonnez-moi un verre d'eau, s'il vous plaît.\\n\n",
              "59998             \\tDonne-moi un coup de main pour ça.\\n\n",
              "59999          \\tDonnez-moi un coup de main pour ceci.\\n\n",
              "Name: tar, Length: 60000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b69ofXWT51_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f584e746-21c7-48ac-d914-a8ee57a54a6a"
      },
      "source": [
        "decoder_target = []\n",
        "for line in lines.tar:\n",
        "  t=0\n",
        "  temp_X=[]\n",
        "  for w in line:\n",
        "    if t>0:\n",
        "      temp_X.append(tar_to_index[w])\n",
        "    t=t+1\n",
        "  decoder_target.append(temp_X)\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[100, 81, 87, 72, 23], [66, 81, 78, 17, 39, 87, 72, 23], [66, 81, 78, 17, 39, 38, 23], [48, 5, 17, 103, 65, 75, 72, 23], [48, 5, 17, 103, 35, 31, 75, 72, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hoUXLyWE6bvh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "03ad7159-d1e8-41e5-f50e-0c0928efb5c2"
      },
      "source": [
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XblblpIb63Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVxnDFwY7E9F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9d2c43b-6617-4d54-be88-e7acc9f98cbb"
      },
      "source": [
        "encoder_input[0][0]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww7ll79n7gn1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "fb4eecd7-5a41-4dcb-8c27-65bb40266b13"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "encoder_input[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sta91D5-79Kz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ab6c0c50-4b42-4c25-ff21-48b011cc3647"
      },
      "source": [
        "encoder_input[0][0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT2jOgiB8A9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "\n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m972NsG791Rs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로 합니다.\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzClj31K_zdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "d5365092-6beb-4890-d8d1-d9c2166198f4"
      },
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=32, epochs=10, validation_split=0.2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 21s 14ms/step - loss: 0.6628 - val_loss: 0.6105\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.4248 - val_loss: 0.4997\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.3599 - val_loss: 0.4501\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.3240 - val_loss: 0.4226\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2999 - val_loss: 0.4045\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.2822 - val_loss: 0.3921\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.2681 - val_loss: 0.3851\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.2565 - val_loss: 0.3783\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 20s 13ms/step - loss: 0.2467 - val_loss: 0.3739\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 19s 13ms/step - loss: 0.2383 - val_loss: 0.3708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0ece531780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sRlvesuAxtJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcpcwhtSBhIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "decoder_states = [state_h, state_c]\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ2cL3znDuhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXHHDXoZD798",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음, 인코더의 h,c를 가지고 온다.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    print('states_value -- ', len(states_value))\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    # (1, 1, 106)의 zero vector가 생성된다.\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용  <SOS>와 encoder에서 나온 h,c를 concat\n",
        "        # 예측된 값들(output_tokens, h, c)이 반환된다.\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :]) # 차원을 1차원으로 줄여준다.\n",
        "        sampled_char = index_to_tar[sampled_token_index] # softmax로 뽑힌 단어.\n",
        "\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        # 결과로 나갈값과 예측할단어를 concat\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO9AIaUJIUvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "162ffc02-c239-409d-dcdd-21747528560f"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [2]: # 입력 문장의 인덱스\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.src[seq_index])\n",
        "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "states_value --  2\n",
            "-----------------------------------\n",
            "입력 문장: Hi.\n",
            "정답 문장: Salut.\n",
            "번역기가 번역한 문장: Aidez-vous.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4Vsrv6YI1NW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}